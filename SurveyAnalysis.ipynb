{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import ML models\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: Helvetica;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "css = open('../Data/style-table.css').read() + open('../Data/style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imports the raw data in chunks. SQL export could not accomodate one CSV dump\n",
    "\n",
    "USMTO1 = pd.DataFrame.from_csv('../Data/USMTO1.csv', index_col = False)\n",
    "USMTO2 = pd.DataFrame.from_csv('../Data/USMTO2.csv', index_col = False)\n",
    "USMTO3 = pd.DataFrame.from_csv('../Data/USMTO3.csv', index_col = False)\n",
    "USMTO4 = pd.DataFrame.from_csv('../Data/USMTO4.csv', index_col = False)\n",
    "USMTO5 = pd.DataFrame.from_csv('../Data/USMTO5.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports raw data for S&P 500 values and Industrial Production\n",
    "\n",
    "SP_500 = pd.DataFrame.from_csv('../Data/SP_500.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#re-combines raw data\n",
    "\n",
    "USMTO_WHOLE = USMTO1.append(USMTO2).append(USMTO3).append(USMTO4).append(USMTO5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merges external data with USMTO data\n",
    "\n",
    "USMTO_WHOLE = USMTO_WHOLE.merge(SP_500, how='inner', on = ['EntryMonth', 'EntryYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#format order date to datetime to prepare for analysis\n",
    "\n",
    "USMTO_WHOLE['OrderDateFormatted'] = pd.to_datetime(USMTO_WHOLE.OrderDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#format changed date to datetime to prepare for analysis\n",
    "\n",
    "USMTO_WHOLE['ChangedDateFormatted'] = pd.to_datetime(USMTO_WHOLE.ChangedDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#format submit date to datetime to prepare for analysis\n",
    "\n",
    "USMTO_WHOLE['SubmitDateFormatted'] = pd.to_datetime(USMTO_WHOLE.SubmitDate.fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#more formatting to get Order Date at End of Month\n",
    "\n",
    "USMTO_WHOLE['hyphen'] = \"-\"\n",
    "\n",
    "USMTO_WHOLE['OrderDateEOM'] = (USMTO_WHOLE.EntryYear.astype(str)) + (USMTO_WHOLE.hyphen) + (USMTO_WHOLE.EntryMonth.astype(str)) + (USMTO_WHOLE.hyphen) + (USMTO_WHOLE.OrderDateFormatted.dt.days_in_month.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#format OrderDateEOM to datetime\n",
    "\n",
    "USMTO_WHOLE['OrderDateEOM'] = pd.to_datetime(USMTO_WHOLE['OrderDateEOM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create column DaysLate which indicates how many days late the order was submitted\n",
    "\n",
    "USMTO_WHOLE['DaysLate'] = (USMTO_WHOLE['SubmitDateFormatted'] - USMTO_WHOLE['OrderDateEOM']).dt.days - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill all NaN with \"0\" -> count=141\n",
    "\n",
    "USMTO_WHOLE['DaysLate'] = USMTO_WHOLE['DaysLate'].fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cast DaysLate and TotalSale as float64\n",
    "\n",
    "USMTO_WHOLE['DaysLate'] = pd.to_numeric(USMTO_WHOLE['DaysLate'])\n",
    "USMTO_WHOLE['TotalSale'] = (USMTO_WHOLE['TotalSale'].replace( '[\\$,)]','', regex=True )\n",
    "               .replace( '[(]','-',   regex=True ).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop un-needed columns\n",
    "\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('SubmitDate', axis=1)\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('OrderDate', axis=1)\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('ChangedDate', axis=1)\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('IsCancel', axis=1)\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('CancelOrderID', axis=1)\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('hyphen', axis=1)\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('IsMatch', axis=1)\n",
    "USMTO_WHOLE = USMTO_WHOLE.drop('IsIgnore', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates columns IsEmailOne, IsEmailTwo, IsCall indicating when reminders are made for a member to submit\n",
    "\n",
    "USMTO_WHOLE['IsEmailOne'] = USMTO_WHOLE['DaysLate'] >= 1\n",
    "USMTO_WHOLE.IsEmailOne = USMTO_WHOLE.IsEmailOne.astype('int')       \n",
    "\n",
    "USMTO_WHOLE['IsEmailTwo'] = USMTO_WHOLE['DaysLate'] >= 5\n",
    "USMTO_WHOLE.IsEmailTwo = USMTO_WHOLE.IsEmailTwo.astype('int')    \n",
    "\n",
    "USMTO_WHOLE['IsCall'] = USMTO_WHOLE['DaysLate'] >= 10\n",
    "USMTO_WHOLE.IsCall = USMTO_WHOLE.IsCall.astype('int')\n",
    "\n",
    "USMTO_WHOLE['IsBackfill'] = USMTO_WHOLE['DaysLate'] >= 90\n",
    "USMTO_WHOLE.IsBackfill = USMTO_WHOLE.IsBackfill.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shows the need to truncate data set\n",
    "\n",
    "USMTO_WHOLE.groupby(['OrderDateFormatted'])['IsEmailOne'].mean().plot(kind = 'line', title = 'Percent Late over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tosses the former half of data which may not be relevant\n",
    "\n",
    "USMTO_WHOLE = USMTO_WHOLE[(USMTO_WHOLE.OrderDateFormatted >= '2006-05-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USMTO_WHOLE.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USMTO_WHOLE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create two new tables, one without outliers (outside 2 stdev), and one without backfillers (defined as submitted later than 100 days - per company definition)\n",
    "\n",
    "USMTO_NO_SUBMIT_OUTLIERS = USMTO_WHOLE[np.abs(USMTO_WHOLE.DaysLate-USMTO_WHOLE.DaysLate.mean())<=(2*USMTO_WHOLE.DaysLate.std())] \n",
    "USMTO_NO_SUBMIT_BACKFILL = USMTO_WHOLE[USMTO_WHOLE.DaysLate <= 90]\n",
    "\n",
    "#source: http://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plots days late in a time series. Exhibit 1A, to be shared with team.\n",
    "\n",
    "USMTO_NO_SUBMIT_BACKFILL.groupby(['OrderDateFormatted'])['DaysLate'].mean().plot(kind = 'line', title = 'Mean Days Late per Month Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#possible causes of change in oscillation\n",
    "#box and whisker plots - how distribution changed over time\n",
    "#change of median, edge, etc?\n",
    "#potential companies that may have joined around 2005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot order submission trend. Exhibit 2\n",
    "\n",
    "USMTO_WHOLE.groupby(['OrderDateFormatted'])['IsSubmitted'].sum().plot(kind = 'line', title = 'Orders Submitted Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plots distribution of days late\n",
    "\n",
    "sns.violinplot(USMTO_NO_SUBMIT_OUTLIERS.DaysLate, title = 'Distribution of Days Late, 1997 to present')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creates table by AAID and OrderDateFormatted\n",
    "\n",
    "AAID_BY_MONTH = USMTO_WHOLE.groupby(['AAID','OrderDateFormatted'])['DaysLate','TotalSale','IsEmailOne', 'IsEmailTwo', 'IsCall', 'IsBackfill','Close','IP'].mean()\n",
    "AAID_BY_MONTH.reset_index(level=1, inplace=True)\n",
    "AAID_BY_MONTH.reset_index(level=1, inplace=True)\n",
    "AAID_BY_MONTH_2 = USMTO_WHOLE.groupby(['AAID','OrderDateFormatted'])['Units','TotalSale'].sum()\n",
    "AAID_BY_MONTH_2.reset_index(level=1, inplace=True)\n",
    "AAID_BY_MONTH_2.reset_index(level=1, inplace=True)\n",
    "AAID_BY_MONTH = AAID_BY_MONTH.merge(AAID_BY_MONTH_2, how = 'inner', on = ['AAID','OrderDateFormatted'])\n",
    "AAID_BY_MONTH['TotalSaleAvg'] = AAID_BY_MONTH['TotalSale_x']\n",
    "AAID_BY_MONTH['TotalSale'] = AAID_BY_MONTH['TotalSale_y']\n",
    "AAID_BY_MONTH = AAID_BY_MONTH.drop('TotalSale_x', axis = 1)\n",
    "AAID_BY_MONTH = AAID_BY_MONTH.drop('TotalSale_y', axis = 1)\n",
    "AAID_BY_MONTH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALL_AAIDS = AAID_BY_MONTH.AAID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#result = pd.DataFrame({'A' : []})\n",
    "\n",
    "#for a in ALL_AAIDS:\n",
    "    #tempdf = AAID_BY_MONTH[AAID_BY_MONTH.AAID == a]\n",
    "    #tempdf['UnitsLast'] = tempdf.Units.shift(1)\n",
    "    #tempdf['IsCallLast'] = tempdf.IsCall.shift(1)\n",
    "    #tempdf['TotalSaleAvgLast'] = tempdf.TotalSaleAvg.shift(1)\n",
    "    #tempdf['TotalSaleLastThree'] = (tempdf.TotalSale.shift(1) +tempdf.TotalSale.shift(2)  + tempdf.TotalSale.shift(3))/3\n",
    "    #tempdf['DaysLastLastThree'] = (tempdf.DaysLate.shift(1) +tempdf.DaysLate.shift(2)  + tempdf.DaysLate.shift(3))/3\n",
    "    #tempdf['DaysLastLast'] = tempdf.DaysLate.shift(1)\n",
    "    #tempdf.fillna(value = 0)\n",
    "    #result.append(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gets rid of all observations that are backfills\n",
    "AAID_BY_MONTH_NO_BACKFILL = AAID_BY_MONTH[AAID_BY_MONTH.DaysLate <= 90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#temporary fill in for adding in feature engineered vars until python script is written\n",
    "\n",
    "AAID_BY_MONTH_NO_BACKFILL.to_csv('../Data/AAIDByMonth',sep = ',')\n",
    "AAID_BY_MONTH_NO_BACKFILL = pd.DataFrame.from_csv('../Data/AAID By Month Edited.csv', index_col = False)\n",
    "AAID_BY_MONTH_NO_BACKFILL['DaysLateLastThree'] = pd.to_numeric(AAID_BY_MONTH_NO_BACKFILL['DaysLateLastThree'])\n",
    "AAID_BY_MONTH_NO_BACKFILL['TotalSaleLastThree'] = pd.to_numeric(AAID_BY_MONTH_NO_BACKFILL['TotalSaleLastThree'])\n",
    "AAID_BY_MONTH_NO_BACKFILL = AAID_BY_MONTH_NO_BACKFILL.fillna(value = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AAID_BY_MONTH_NO_BACKFILL.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create column \"Three MMA Late\" - which models the average of the past three month's lateness for each company\n",
    "\n",
    "#AAID_BY_MONTH_NO_BACKFILL['Three_MMA_Late'] = AAID_BY_MONTH_NO_BACKFILL.DaysLate.ewm(span=3).mean()\n",
    "#AAID_BY_MONTH_NO_BACKFILL.groupby(['OrderDateFormatted'])['Three_MMA_Late'].mean().plot(kind = 'line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#AAID_BY_MONTH_NO_BACKFILL['Three_MMA_SalesTrend'] = AAID_BY_MONTH_NO_BACKFILL.TotalSale.ewm(span=3).mean()\n",
    "#AAID_BY_MONTH_NO_BACKFILL.groupby(['OrderDateFormatted'])['Three_MMA_SalesTrend'].sum().plot(kind = 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scatter matrix identifying key features - target excluded\n",
    "\n",
    "PAIRPLOT2 = AAID_BY_MONTH_NO_BACKFILL\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('AAID', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('OrderDateFormatted', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('IsEmailOne', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('IsEmailTwo', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('IsBackfill', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('DaysLate', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('TotalSaleAvg', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('Units', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('TotalSale', axis = 1)\n",
    "\n",
    "sns.pairplot(PAIRPLOT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DaysLate Last vs Days Late (suspicious line - business reason for this, not data error)\n",
    "\n",
    "AAID_BY_MONTH_NO_BACKFILL.plot.scatter('DaysLate','DaysLateLast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average sales over time\n",
    "\n",
    "BY_MONTH = AAID_BY_MONTH.groupby(['OrderDateFormatted']).sum()\n",
    "BY_MONTH.reset_index(level=1, inplace=True)\n",
    "BY_MONTH.plot(x='OrderDateFormatted', y='TotalSale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot of orders submitted over time\n",
    "\n",
    "USMTO_WHOLE.groupby(['OrderDateFormatted'])['TotalSale'].sum().plot(kind = 'line', title = 'Orders Submitted Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentage of company by month who needed to be called\n",
    "\n",
    "BY_MONTH = AAID_BY_MONTH.groupby(['OrderDateFormatted']).mean()\n",
    "BY_MONTH.reset_index(level=1, inplace=True)\n",
    "BY_MONTH.plot(x='OrderDateFormatted', y='IsCall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentage of company by month who needed to have first email sent\n",
    "\n",
    "BY_MONTH = AAID_BY_MONTH.groupby(['OrderDateFormatted']).mean()\n",
    "BY_MONTH.reset_index(level=1, inplace=True)\n",
    "BY_MONTH.plot(x='OrderDateFormatted', y='IsEmailOne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#percentage of company by month who needed to have second email sent\n",
    "\n",
    "BY_MONTH = AAID_BY_MONTH.groupby(['OrderDateFormatted']).mean()\n",
    "BY_MONTH.reset_index(level=1, inplace=True)\n",
    "BY_MONTH.plot(x='OrderDateFormatted', y='IsEmailTwo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#percentage of company by month who backfilled\n",
    "\n",
    "BY_MONTH = AAID_BY_MONTH.groupby(['OrderDateFormatted']).mean()\n",
    "BY_MONTH.reset_index(level=1, inplace=True)\n",
    "BY_MONTH.plot(x='OrderDateFormatted', y='IsBackfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prep for correlation matrix - target included. also the dataframe for machine learning algorithms\n",
    "\n",
    "PAIRPLOT2 = AAID_BY_MONTH_NO_BACKFILL\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('AAID', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('OrderDateFormatted', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('IsEmailOne', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('IsEmailTwo', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('IsBackfill', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('DaysLate', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('TotalSaleAvg', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('Units', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('TotalSale', axis = 1)\n",
    "#PAIRPLOT2 = PAIRPLOT2.drop('DaysLateLast', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('Three_MMA_Late', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('Three_MMA_SalesTrend', axis = 1)\n",
    "PAIRPLOT2 = PAIRPLOT2.drop('DaysLateLast', axis = 1)\n",
    "\n",
    "\n",
    "corr2 = PAIRPLOT2.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PAIRPLOT2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Class Distribution\n",
    "\n",
    "AAID_BY_MONTH_NO_BACKFILL.groupby('IsCall').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Skew of Attributes\n",
    "\n",
    "PAIRPLOT2.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PAIRPLOT2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Correlation Matrix Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr2, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr2, mask=mask, cmap=cmap, vmax=.3,\n",
    "            square=True, xticklabels=True, yticklabels=True,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rescales all data to be between 0 and 1 and readies it for further processing - in progress\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "array = PAIRPLOT2.values\n",
    "# separate array into input and output components\n",
    "X = array[:,1:14]\n",
    "Y = array[:,0]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "#rescaledX3 = rescaledX.reshape((-1,8))\n",
    "\n",
    "#rescaledX3 = pd.DataFrame({'IsCall':rescaledX[:,0],'Close':rescaledX[:,1],'Three_MMA_Late':rescaledX[:,2],'Three_MMA_SalesTrend':rescaledX[:,3],'DaysLateLastThree':rescaledX[:,4],'TotalSaleLastThree':rescaledX[:,5],'DaysLateLast':rescaledX[:,6],'UnitsLast':rescaledX[:,7],'IsCallLast':rescaledX[:,8]})\n",
    "#sns.boxplot(data = rescaledX3, orient = 'h', fliersize = '.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PAIRPLOT2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rescaledX3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#relationship between last month's days late and this month's call\n",
    "\n",
    "#rescaledX3.plot.scatter('DaysLateLast','IsCall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#columns which correspond to feature selection output\n",
    "\n",
    "PAIRPLOT2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14]\n",
    "Y = array[:,0]\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction with RFE \n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load data\n",
    "\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14]\n",
    "Y = array[:,0]\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 4)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: \" , fit.n_features_)\n",
    "print(\"Selected Features: \" , fit.support_)\n",
    "print(\"Feature Ranking: \" , fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Feature Extraction with PCA - in progress\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14]\n",
    "Y = array[:,0]\n",
    "# feature extraction\n",
    "pca = PCA(n_components=4)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: \", fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we end up using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test different types of models\n",
    "\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14].astype(float)\n",
    "Y = array[:,0]\n",
    "validation_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y,\n",
    "test_size=validation_size, random_state=seed)\n",
    "num_folds = 5\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC())) - causes code to hang\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = (name, cv_results.mean(),cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distribution of models, accuracy and std dev\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PAIRPLOT2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'a':X[:,0],'b':X[:,1],'c':X[:,2],'d':X[:,3],'e':X[:,4],'f':X[:,5],'g':X[:,6]}).head()\n",
    "\n",
    "print (a.columns)\n",
    "print (PAIRPLOT2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn import tree\n",
    ">>>\n",
    ">>> clf = tree.DecisionTreeClassifier()\n",
    ">>> clf = clf.fit(X_train, Y_train)\n",
    ">>> tree.export_graphviz(clf,\n",
    "...     out_file='usmto3.dot',feature_names = a.columns)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.externals.six import StringIO\n",
    ">>> with open(\"usmto3.dot\", 'w') as f:\n",
    "...     f = tree.export_graphviz(clf, out_file=f)\n",
    "\n",
    ">>> import os\n",
    ">>> os.unlink('usmto3.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classification report with best model (Decision Trees)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14]\n",
    "Y = array[:,0]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y,\n",
    "test_size=test_size, random_state=seed)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation Classification LogLoss (smaller logloss better with 0 as perfect logloss)\n",
    "\n",
    "\n",
    "from sklearn import cross_validation\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14]\n",
    "Y = array[:,0]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "scoring = 'log_loss'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring = scoring)\n",
    "print(\"Logloss: \", results.mean(), \"      Std Dev: \", results.std()*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation Classification with Area Under the Curve (Between 0.5 and 1 indicates good model)\n",
    "\n",
    "\n",
    "from sklearn import cross_validation\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14]\n",
    "Y = array[:,0]\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 7\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "scoring = 'roc_auc'\n",
    "results = cross_validation.cross_val_score(model, X, Y, cv=kfold, scoring = scoring)\n",
    "print(\"AUC: \", results.mean(), \"      Std Dev: \", results.std()*100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "********BREAK**********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Import some data to play with\n",
    "array = PAIRPLOT2.values\n",
    "X = array[:,1:14]\n",
    "y = array[:,0]\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         linewidth=2)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         linewidth=2)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#APPENDIX AS FOLLOWS: (works in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cols to create:\n",
    "\n",
    "#3 MMA company sales\n",
    "#3 MMA lateness\n",
    "# s&p 500 \n",
    "machine tool mix\n",
    "#prior month late days\n",
    "# scatter matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attempts to map which AAIDs submitted over what dates\n",
    "\n",
    "AAIDs = pd.DataFrame.from_csv('AAIDs.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AAIDs = AAIDs.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AAIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plots distribution who received a first email, over all time\n",
    "\n",
    "USMTO_WHOLE.groupby('OrderDateFormatted')['IsEmailOne'].mean().plot(kind = 'hist',bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USMTO_WHOLE.groupby('OrderDateFormatted')['IsEmailTwo'].mean().plot(kind = 'hist',bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USMTO_WHOLE.groupby('OrderDateFormatted')['IsCall'].mean().plot(kind = 'hist',bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "USMTO_WHOLE.groupby('OrderDateFormatted')['IsBackfill'].mean().plot(kind = 'hist',bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USMTO_WHOLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
